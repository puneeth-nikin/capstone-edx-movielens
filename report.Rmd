---
title: "Movielens Project Report"
author: "Puneeth Nikin Krishnan"
date: "30/04/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Executive Summary

The objective of this project is to develop a recommendation system based on the movielens Dataset. To achieve this ratings need to be predicted for a user based on past ratings. The goal here is to accurately predict ratings. To be able to gauge the performance of different models RMSE (Root Mean Square Error) will be used. The dataset has been split into two sets, one for training(edx) and the other testing(validation) our model. The validation set will not be used, except to validate the best performing model. The training set will be further split into a train set and a test set to identify the best model. The best model will be one which has the least RMSE. The steps followed to build this model are first importing the dataset, preparing the dataset, exploring or analysing the dataset, building the models, choosing the best model and finally validating the results on the validation set.

### Importing the Dataset
The code to import the dataset has been proveded by edx. 
[link to import dataset](https://courses.edx.org/login?next=/courses/course-v1%3AHarvardX%2BPH125.9x%2B1T2020/courseware/dd9a048b16ca477a8f0aaf1d888f0734/e8800e37aa444297a3a2f35bf84ce452/%3Fchild%3Dlast)

```{r import data,message = FALSE,warning = FALSE, echo = FALSE}
################################
# Create edx set, validation set
################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding")
# if using R 3.5 or earlier, use `set.seed(1)` instead
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)

```

Running the code will give us two dataframes namely edx and validation. The edx dataframe will be used to build our model.

```{r libraries,echo=FALSE,message = FALSE,warning = FALSE} 
library(caret)
library(tidyverse)
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
library(lubridate)
library(stringr)
if(!require(knitr)) install.packages("knitr", repos = "http://cran.us.r-project.org")
if(!require(kableExtra)) install.packages("kableExtra", repos = "http://cran.us.r-project.org")
library(knitr)
library(kableExtra)

```

### Exploring and Preparing the Dataset
```{r}
dim(edx)
```

We notice that the dataset is pretty huge with 9,000,055 rows and 6 columns

```{r message = FALSE,warning = FALSE}
names(edx)
edx%>%head()%>%knitr::kable()
```

The edx dataframe comprises of 5 columns. 'userId' represents the unique user ID, 'movieId' represents the unique ID for each movie, timestamp denotes the time of the rating, title represents title and genres the combination of genres.
Each row represents one rating by a user.
We can notice that the title section contains the year the movie was released in. We will use regex to extract the year released from this column. The regex pattern used to extract the data is "(\\d{4})\\)$" . This can be  evidenced by the fact that the year is at the end of  the string in column title. We use the str_match() function  from the stringr package to  extract the year and convert to a date format using  the as.date() and year() functions from the  lubridate package.


```{r message = FALSE,warning = FALSE}
# extracting the year released from the title column
regex_pattern<-"(\\d{4})\\)$"
edx<-edx%>%
  mutate(year_released=year(as.Date(str_match(title,regex_pattern)[,2],format="%Y")))
edx%>%head()%>%
  knitr::kable()%>%kable_styling(latex_options = c("striped", "scale_down"))
```

We can convert the timestamp column to a readable datetime object using the as_datetime() from the lubridate package

```{r message = FALSE,warning = FALSE}
# converting the timestamp column to readable date
edx <- edx%>%
  mutate(datetime=as_datetime(timestamp))
edx%>%
  head()%>%
  knitr::kable()%>%kable_styling(latex_options = c("striped", "scale_down"))
```

## Exploring the relationship between ratings and the year the movie was released


```{r message = FALSE,warning = FALSE}
#exploring relation between ratings and the year movie was released

edx%>%
  group_by(year_released)%>%
  summarise(avg_ratings=mean(rating))%>%
  ggplot(aes(year_released,avg_ratings))+
  geom_point()+
  geom_smooth(method = "loess")+
  theme(axis.text.x = element_text(angle = 90,hjust = 1))+
  ggtitle("Average ratings vs Year Released")
edx%>%
  group_by(year_released)%>%
  summarise(n_ratings=n())%>%
  ggplot(aes(year_released,n_ratings))+
  geom_point()+
  geom_smooth(method = "loess")+
  theme(axis.text.x = element_text(angle = 90,hjust = 1))+
  ggtitle("Number of Ratings vs Year Released ")

```

The first plot shows that there is a clear dip in ratings for movies that were released after the late 1980s. There could be a relationship between the year the movie was released and the ratings as there are two clear clusters.
In the second plot shows that  post 1993 the number of ratings for movies shot up while also showing a  rapid declining  pattern post that.

## Exploring the relationship between ratings and when the movie was rated


```{r message = FALSE,warning = FALSE}
edx%>%
  mutate(week_rated=round_date(datetime,unit = 'week'))%>%
  group_by(week_rated)%>%
  summarise(avg_rating=mean(rating))%>%
  ggplot(aes(week_rated,avg_rating))+
  geom_point()+
  geom_smooth(method="loess")+
  ggtitle("Average Rating vs Timestamp of Rating")
edx%>%
  mutate(week_rated=round_date(datetime,unit = 'week'))%>%
  group_by(week_rated)%>%
  summarise(n_rating=n())%>%
  ggplot(aes(week_rated,n_rating))+
  geom_point()+
  geom_smooth(method="loess")+
  ggtitle("Number of Ratings vs Timestamp of Rating")
```

The relationship does not seem to be strong between the year as a predictor and ratings. We can safely ignore the timestamp of rating for predicting the ratings.

## Exploring the relationship between ratings and different genres.

```{r message = FALSE,warning = FALSE}
unique(unlist(str_split(as.vector(unique(edx$genres)),"\\|")))
```

```{r message = FALSE,warning = FALSE}
length(unique(edx$genres))
```

There are 20 unique genres and 797 unique combination of these genres(including "(no genres listed)").

```{r message = FALSE,warning = FALSE}
edx%>%group_by(genres)%>%
  summarise(avg_ratings=mean(rating))%>%
  top_n(10,avg_ratings) %>% 
  knitr::kable(caption = "Top 10 genres by rating")

```


```{r  message = FALSE,warning = FALSE}
edx%>%group_by(genres)%>%
  summarise(avg_ratings=mean(rating),n_ratings=n())%>%
  top_n(10,n_ratings)%>%
  knitr::kable(caption = "Top 10 genres by number of ratings")
```

This shows that the most rated movies are not necessarily the best rated.

```{r message = FALSE,warning = FALSE}
edx%>%group_by(genres)%>%
  summarise(avg_rating=mean(rating),
            se_rating=sd(rating)/sqrt(n()),
            n_ratings=n())%>%
  top_n(15,n_ratings)%>%mutate(genres=reorder(genres,avg_rating))%>%
  ggplot(aes(x=genres,
             y=avg_rating,
             ymin=avg_rating-(qnorm(0.975)*se_rating),
             ymax=avg_rating+(qnorm(0.975)*se_rating)))+
  geom_errorbar()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  ggtitle("Error Bar plots Top rated genres vs average ratings")+ylab('rating')
```

As can be seen in this plot it is clear that  there is a definite distinction between the genres. From this analysis we can conclude that genres  have a relationship with ratings.

## Exploring the relationship  between ratings and user

```{r message = FALSE,warning = FALSE}
edx%>%
  group_by(userId)%>%
  summarise(n_ratings=n())%>%
  ggplot(aes(x=n_ratings))+
  geom_histogram(bins=50,color='black')+
  scale_x_continuous(trans = 'log10')+
  ggtitle("Count vs users number of ratings")
```
This plot shows that the number of users who rate over a 1000 are very  less whereas the average user votes about 25 to 100 movies.

## Exploring the relationship  between ratings and movie

```{r message = FALSE,warning = FALSE}
edx%>%
  group_by(movieId)%>%
  summarise(n_ratings=n())%>%
  ggplot(aes(x=n_ratings))+
  geom_histogram(bins=50,color='black')+
  scale_x_continuous(trans = 'log10')+
  ggtitle("Count vs number of ratings for Movies")
```

This plot shows that some movies are rated way more often than others.

## Inference from our Analysis
1) Movies that were released before 1990s have a higher  rating than  movies that were released later.
2) Some genres are more popular than others while some have a higher rating. 
3) Some Users tend to be very active in rating while others are not. This could also  mean that some users tend to watch a lot of movies.
4)Some movies are popular than others  and tend to have many more ratings. 

The goal of  our model is to incorporate these findings in our model  to accurately predict  ratings.


### Building the Model

## RMSE

Here we define a function to measure the performance  of the model.

```{r message = FALSE,warning = FALSE}
RMSE <-  function(predicted_ratings,actual_ratings){
  sqrt(mean((predicted_ratings-actual_ratings)^2))
}
```
A tibble to  store all  our results
```{r message = FALSE,warning = FALSE}
results<-tibble()
```

## Split edx to train_set and  test_set

The caret package provides createDataPartition( function). Using this function we divide the edx dataset to train and test set. To replicate the split the seed has been set to 1. Lastly to ensure that the test_set has the same set of movies and users the semi_join() function from the tidyverse package is used.
```{r message = FALSE,warning = FALSE}
#split edx to train and test set
set.seed(1, sample.kind="Rounding")
# if using R 3.5 or earlier, use `set.seed(1)` instead
test_index<-createDataPartition(edx$rating,times=1,p=0.5,list=FALSE)
test_set<-edx[test_index,]
train_set<-edx[-test_index,]
#ensuring the test set has same userId and movieId
test_set <- test_set %>% semi_join(train_set, by = "movieId") %>% 
  semi_join(train_set, by = "userId")
```

## simplest model

```{r message = FALSE,warning = FALSE}
mu<-mean(train_set$rating)
result_simple_model<-RMSE(mu,test_set$rating)
results<-data.frame(model='Mean Only',result=result_simple_model)
```
We start the process  by building the simplest possible model where we assume that all movies are rated equally and use the result as the base for our  upcoming models.

## Movie Effect b_i

We have seen that different movies have different level of popularity and are rated differently. Here we attempt to incorporate this effect into the model.

```{r message = FALSE,warning = FALSE}

avg_ratings_movie<- train_set%>%
  group_by(movieId)%>%
  summarise(b_i=mean(rating)-mu)
predictions_movie_effect <- mu + 
  test_set%>%
  left_join(avg_ratings_movie,by='movieId')%>% 
  pull(b_i)
result_movie_effect<-RMSE(predictions_movie_effect,test_set$rating)
results<-rbind(results,
               data.frame(model='Movie Effect',
                          result=result_movie_effect))
```


## Movie Effect + User Effect b_u

Smilar to movies users also have different biases. Consequentially some users tend to rate movies higher while some rate the same movies lower. Here we incorporate this bias into the model.

```{r message = FALSE,warning = FALSE}
avg_ratings_user  <- train_set%>%
  left_join(avg_ratings_movie,by='movieId')%>%
  group_by(userId)%>%
  summarise(b_u= mean(rating-mu-b_i))
predictions_movie_user_effect <- test_set%>%
  left_join(avg_ratings_movie,by='movieId')%>%
  left_join(avg_ratings_user,by='userId')%>%
  mutate(pred=mu+b_i+b_u)%>%
  pull(pred)
result_movie_user_effect<-RMSE(predictions_movie_user_effect,test_set$rating)
results<-rbind(results,
               data.frame(model='Movie+User Effect',
                          result=result_movie_user_effect))
```

## Movie Effect + User Effect +Genre Effect b_g

Our analysis also shows that some genres tend to be more popular than others. Here we incorporate this bias into the model.

```{r message = FALSE,warning = FALSE}
avg_ratings_genre<-train_set %>%
  left_join(avg_ratings_movie,by='movieId')%>%
  left_join(avg_ratings_user,by='userId')%>%
  group_by(genres)%>%summarise(b_g=mean(rating-mu-b_i-b_u))
predictions_movie_user_genre_effect<- test_set%>%
  left_join(avg_ratings_movie,by='movieId')%>%
  left_join(avg_ratings_user,by='userId')%>%
  left_join(avg_ratings_genre,by='genres')%>%
  mutate(pred=mu+b_i+b_u+b_g)%>%pull(pred)
result_movie_user_genre_effect<-RMSE(predictions_movie_user_genre_effect,
                                     test_set$rating)
results <- rbind(results,
                 data.frame(model='Movie+User+Genre Effect',
                            result=result_movie_user_genre_effect))
```

## Movie Effect + User Effect +Genre Effect + year realeased effect b_g

Finally there was a clear distinction in ratings when it came to the year movies where released in. Especially with movies that were releases before the 1990s. This snippet of code incorporates that bias in the model.

```{r message = FALSE,warning = FALSE}
avg_ratings_year<-train_set%>%
  left_join(avg_ratings_movie,by='movieId')%>%
  left_join(avg_ratings_user,by='userId')%>%
  left_join(avg_ratings_genre,by='genres')%>%
  group_by(year_released)%>%
  summarise(b_t=mean(rating-mu-b_i-b_u-b_g))
predictions_movie_user_genre_year_effect<-test_set%>%
  left_join(avg_ratings_movie,by='movieId')%>%
  left_join(avg_ratings_user,by='userId')%>%
  left_join(avg_ratings_genre,by='genres')%>%
  left_join(avg_ratings_year,by='year_released')%>%
  mutate(pred=mu+b_i+b_u+b_g+b_t)%>%pull(pred)
result_movie_user_genre_year_effect<-RMSE(predictions_movie_user_genre_year_effect,
                                          test_set$rating)
results<-rbind(results,
               data.frame(model='Movie+User+genre+year_released Effect',
                          result=result_movie_user_genre_year_effect))
```

## Regularisation

```{r message = FALSE,warning = FALSE}
results%>%knitr::kable()
```
As can be seen from the results above for each additional effect the RMSE has come down. To improve upon this result we regularise the dataset. By regularisation we will penalise large estimates for movies with few ratings.

```{r message = FALSE,warning = FALSE}
lambdas <- seq(0, 10, 0.5)
regularisation_function <- function(lambda){
  mu <- mean(train_set$rating)
  avg_ratings_movie<-train_set%>%
    group_by(movieId)%>%
    summarise(b_i=sum(rating-mu)/(n()+lambda))
  avg_ratings_user<-train_set%>%
    left_join(avg_ratings_movie,by='movieId')%>%
    group_by(userId)%>%summarise(b_u= sum(rating-mu-b_i)/(n()+lambda))
  avg_ratings_genre<-train_set %>%
    left_join(avg_ratings_movie,by='movieId')%>%
    left_join(avg_ratings_user,by='userId')%>%
    group_by(genres)%>%summarise(b_g=sum(rating-mu-b_i-b_u)/(n()+lambda))
  avg_ratings_year<-train_set%>%left_join(avg_ratings_movie,by='movieId')%>%
    left_join(avg_ratings_user,by='userId')%>%
    left_join(avg_ratings_genre,by='genres')%>%
    group_by(year_released)%>%
    summarise(b_t=sum(rating-mu-b_i-b_u-b_g)/(n()+lambda))
  predictions<-test_set%>%
    left_join(avg_ratings_movie,by='movieId')%>%
    left_join(avg_ratings_user,by='userId')%>%
    left_join(avg_ratings_genre,by='genres')%>%
    left_join(avg_ratings_year,by='year_released')%>%
    mutate(pred=mu+b_i+b_u+b_g+b_t)%>%pull(pred)
  RMSE(predictions,test_set$rating)
} 
rmses_regularised <- map_dbl(lambdas, regularisation_function)

```

## Choosing Lambda (tuning parameter)
```{r message = FALSE,warning = FALSE}
best_lambda<-lambdas[which.min(rmses_regularised)]
results<- rbind(results,
                data.frame(model='Movie+User+genre+year_released Effect with Regularisation',
                           result=min(rmses_regularised)))


```


## Training on the edx dataset

```{r message = FALSE,warning = FALSE}
results%>% knitr::kable()
```

Based on this we choose 'Movie+User+genre+year_released Effect with Regularisation' as the best model and train our model on the edx dataset.

```{r message = FALSE,warning = FALSE}
mu<-mean(edx$rating)
avg_ratings_movie<-edx%>%
  group_by(movieId)%>%
  summarise(b_i=sum(rating-mu)/(n()+best_lambda))
avg_ratings_user<-edx%>%
  left_join(avg_ratings_movie,by='movieId')%>%
  group_by(userId)%>%
  summarise(b_u= sum(rating-mu-b_i)/(n()+best_lambda))
avg_ratings_genre<-edx %>%
  left_join(avg_ratings_movie,by='movieId')%>%
  left_join(avg_ratings_user,by='userId')%>%
  group_by(genres)%>%
  summarise(b_g=sum(rating-mu-b_i-b_u)/(n()+best_lambda))
avg_ratings_year<-edx%>%
  left_join(avg_ratings_movie,by='movieId')%>%
  left_join(avg_ratings_user,by='userId')%>%
  left_join(avg_ratings_genre,by='genres')%>%
  group_by(year_released)%>%
  summarise(b_t=sum(rating-mu-b_i-b_u-b_g)/(n()+best_lambda))


```

```{r message = FALSE,warning = FALSE}
validation<-validation%>%
  mutate(year_released=year(as.Date(str_match(title,regex_pattern)[,2],format="%Y")))
predictions<-validation%>%
  left_join(avg_ratings_movie,by='movieId')%>%
  left_join(avg_ratings_user,by='userId')%>%
  left_join(avg_ratings_genre,by='genres')%>%
  left_join(avg_ratings_year,by='year_released')%>%
  mutate(pred=mu+b_i+b_u+b_g+b_t)%>%pull(pred)
final_result<-RMSE(predictions,validation$rating)

```

### Result

```{r message = FALSE,warning = FALSE}
print(c("RMSE_final <- ",final_result))
```

The best model has resulted in a significant improvement to our RMSE and our final RMSE is 0.86429.



